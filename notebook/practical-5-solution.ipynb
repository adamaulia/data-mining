{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ca3c5e",
   "metadata": {},
   "source": [
    "## Practical 5\n",
    "\n",
    "In this practical, we will focus on conducting reproducible and robust research. We will piece together most parts of the knowledge we have gathered in the course. Therefore, this practical can be seen as writing a mini-thesis, or at the very least a proposal for one. Please note that these are by no means strict guidelines, and they only scratch the surface. We hope you find that it will feature some useful tips and tricks you will be able to apply in the future (like all prior notebooks). Unlike the previous practicals, there will not be tasks leading to questions for you to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c42626",
   "metadata": {},
   "source": [
    "### The initial idea\n",
    "\n",
    "The motivation of the exercises of this notebook is based on the DeepMoji model, a sentiment classifier. In particular, we will collect the same type of data, train a sentiment classifier, and see if the techniques they use can generalize to different data (i.e., to a different domain).\n",
    "\n",
    "It should be mentioned that DeepMoji was trained on Tweets, so we will test if it can also predict the sentiment of Yelp (restaurant) reviews. For a technique to be a ‚Äògeneral‚Äô sentiment predictor, it should work on these reviews. This contribution is our scientific relevance. Then, what is the societal relevance? Sentiment analysis has a broad application in marketing, social sciences, crisis analyses, etc. \n",
    "\n",
    "Therefore, our proposal will also include simple models, explainable models, which we can compare to the DeepMoji.\n",
    "\n",
    "This brings us to the research question(s):\n",
    "- To what extent can we reproduce the DeepMoji paper?\n",
    "- How closely can we match performance with a new dataset?\n",
    "- Do simple classifiers achieve comparable performance?\n",
    "- Does our model generalize to a different domain?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b810a28",
   "metadata": {},
   "source": [
    "### Data\n",
    "Note: We have already gathered the data for this practical and you do not have to execute the following code. This part is for information only.\n",
    "\n",
    "We start by setting up the collection of data from Twitter. The Twitter API allows you to access part of their data after  registering for keys in this link:\n",
    "https://developer.twitter.com/en\n",
    "(Twitter account required). \n",
    "\n",
    "We use ``tweepy``, you can see more info on https://cmry.github.io/notes/twitter-python). As such:\n",
    "\n",
    "```\n",
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(\"XXXX\", \"XXXX\")\n",
    "auth.set_access_token(\"XXXX\", \"XXXX\")\n",
    "api = tweepy.API(auth)\n",
    "```\n",
    "\n",
    "The \"XXXX\" parts are where your own keys should go after you register. We then have this piece of code for retrieval:\n",
    "\n",
    "```\n",
    "from time import sleep\n",
    "\n",
    "for n_queries in range(120):\n",
    "\n",
    "    with open('emoji-data.txt', 'a') as of:\n",
    "        emoji_dict = {\"üôÇ\": \"happy\", \"üôÅ\": \"sad\", \"üò†\": \"angry\", \"‚ù§Ô∏è\": \"love\"}\n",
    "        for emoji, label in emoji_dict.items():\n",
    "            for tweet in api.search(emoji, lang=\"en\", include_entities=False):\n",
    "                jsf = tweet._json\n",
    "                jsf.pop('metadata')\n",
    "                jsf.pop('user')\n",
    "                try:\n",
    "                    jsf.pop('entities')\n",
    "                except:\n",
    "                    pass\n",
    "                of.write(label + \" | \" + str(jsf) + \"\\n\")\n",
    "        sleep(30)\n",
    "```\n",
    "\n",
    "**Code explained.** The dictionary keys contain emojis. First, we perform 120 queries and append them to our data file (notice that we can restart the code and keep collecting). Per emoji in our dictionary, we launch a separate query (api.search), restrict the language to English, and do not include a bunch of extra information. Next, we remove some additional stuff from the JSON for each tweet in the retrieved data and then write the return object plus our label to file. Finally, we need to wait 30 seconds between each query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb7cd71",
   "metadata": {},
   "source": [
    "#### Testing our Data\n",
    "A logical first step before anything else would be to see if the models trained on our data work. If we can‚Äôt predict emojis (or sentiment, rather) for a test set with other Tweets, we cannot really hope to perform well on a benchmark set, let alone out-of-domain data. The collected is provided with this notebook. The data is stored in a ``<label> | <JSON_file>`` format, which we first have to split. This will give us a line as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0371ef26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy | {\\'created_at\\': \\'Sat Oct 10 22:33:51 +0000 2020\\', \\'id\\': 1315057988470743041, \\'id_str\\': \\'1315057988470743041\\', \\'text\\': \\'@melemel2012 @JackPosobiec Great parenting üòä\\', \\'truncated\\': False, \\'source\\': \\'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>\\', \\'in_reply_to_status_id\\': 1314987700018130944, \\'in_reply_to_status_id_str\\': \\'1314987700018130944\\', \\'in_reply_to_user_id\\': 412322037, \\'in_reply_to_user_id_str\\': \\'412322037\\', \\'in_reply_to_screen_name\\': \\'melemel2012\\', \\'geo\\': None, \\'coordinates\\': None, \\'place\\': None, \\'contributors\\': None, \\'is_quote_status\\': False, \\'retweet_count\\': 0, \\'favorite_count\\': 0, \\'favorited\\': False, \\'retweeted\\': False, \\'lang\\': \\'en\\'}'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'research/'\n",
    "open(data_dir + 'emoji-data.txt', encoding=\"utf8\").read().split('\\n')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9be4b",
   "metadata": {},
   "source": [
    "**Important note.** We have added the parameter `encoding=\"utf8\"` to read this file properly in Python 3, otherwise we might get a encoding error and we could not continue. The next line splits the label and the JSON in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45672589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happy ',\n",
       " ' {\\'created_at\\': \\'Sat Oct 10 22:33:51 +0000 2020\\', \\'id\\': 1315057988470743041, \\'id_str\\': \\'1315057988470743041\\', \\'text\\': \\'@melemel2012 @JackPosobiec Great parenting üòä\\', \\'truncated\\': False, \\'source\\': \\'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>\\', \\'in_reply_to_status_id\\': 1314987700018130944, \\'in_reply_to_status_id_str\\': \\'1314987700018130944\\', \\'in_reply_to_user_id\\': 412322037, \\'in_reply_to_user_id_str\\': \\'412322037\\', \\'in_reply_to_screen_name\\': \\'melemel2012\\', \\'geo\\': None, \\'coordinates\\': None, \\'place\\': None, \\'contributors\\': None, \\'is_quote_status\\': False, \\'retweet_count\\': 0, \\'favorite_count\\': 0, \\'favorited\\': False, \\'retweeted\\': False, \\'lang\\': \\'en\\'}']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(data_dir + 'emoji-data.txt', encoding=\"utf8\").read().split('\\n')[0].split('|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2bf4c2",
   "metadata": {},
   "source": [
    "If we select the first element, we can see the JSON. As it was not saved before, we have to use `eval()` to convert it back to a JSON / dictionary format and visualize it in the form of dictionary as visualized below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a7e3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Sat Oct 10 22:33:51 +0000 2020',\n",
       " 'id': 1315057988470743041,\n",
       " 'id_str': '1315057988470743041',\n",
       " 'text': '@melemel2012 @JackPosobiec Great parenting üòä',\n",
       " 'truncated': False,\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'in_reply_to_status_id': 1314987700018130944,\n",
       " 'in_reply_to_status_id_str': '1314987700018130944',\n",
       " 'in_reply_to_user_id': 412322037,\n",
       " 'in_reply_to_user_id_str': '412322037',\n",
       " 'in_reply_to_screen_name': 'melemel2012',\n",
       " 'geo': None,\n",
       " 'coordinates': None,\n",
       " 'place': None,\n",
       " 'contributors': None,\n",
       " 'is_quote_status': False,\n",
       " 'retweet_count': 0,\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'retweeted': False,\n",
       " 'lang': 'en'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(open(data_dir + 'emoji-data.txt', encoding=\"utf8\").read().split('\\n')[0].split('|')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910ba94",
   "metadata": {},
   "source": [
    "Given the latter output, you can see that we have a bunch of extra information that came with the Twitter API, such as the date, the number of likes, retweets, the geolocation (if provided), and the text of the tweet itself. Next, we essentially apply the operations above (splitting the lines, evaluating the JSON part) but then append them to two lists (one for text and one for labels). These are at the end stored in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d32a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text, labels = [], []\n",
    "for line in open(data_dir + 'emoji-data.txt', encoding=\"utf8\").read().split('\\n'):\n",
    "    try:\n",
    "        label, jsonf = line.split(' | ')\n",
    "        text.append(eval(jsonf)['text'])\n",
    "        labels.append(label)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a807182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@melemel2012 @JackPosobiec Great parenting üòä</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @copter_chief: .@realDonaldTrump Once AG Ba...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@mummybunz21 @shawneda @TheSims @TheSimCommuni...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @JSimoncavage: I know I'm cute and this is ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @GoldenTreeCIC: Repeat daily and develop a ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text labels\n",
       "0       @melemel2012 @JackPosobiec Great parenting üòä  happy\n",
       "1  RT @copter_chief: .@realDonaldTrump Once AG Ba...  happy\n",
       "2  @mummybunz21 @shawneda @TheSims @TheSimCommuni...  happy\n",
       "3  RT @JSimoncavage: I know I'm cute and this is ...  happy\n",
       "4  RT @GoldenTreeCIC: Repeat daily and develop a ...  happy"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'text': text, 'labels': labels})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa835bb0",
   "metadata": {},
   "source": [
    "To save memory, we are going to delete our text and label variables, as they are in the DataFrame now anyways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58c9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "del text, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424befe",
   "metadata": {},
   "source": [
    "Let‚Äôs see what labels we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac5b1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = df.labels.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9601055d",
   "metadata": {},
   "source": [
    "You will notice that these are all nicely distributed (this happens because the data was collected that way). Now, we could go through the effort of fitting a classifier we the data we have and confirm that the prediction performances on the test are pretty low.\n",
    "\n",
    "However, this time we will spoil the problem immediately: there are duplicate tweets in this dataset. \n",
    "\n",
    "Generally, that means that the classifier will overfit these particular tweets, and therefore perform poorly on others. Moreover, another issue is that our data is not that big (one hour's worth of data is not much). For completeness, we will go through solving the duplicates issue and assessing the evaluation scores. First, we want to drop the overlapping tweets, which we can do with Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a3d5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13070\n",
      "5922\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "df.drop_duplicates(subset=['text'], inplace=True)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8826d62",
   "metadata": {},
   "source": [
    "Note that subset is used to indicate the column where we want to detect the duplicates, and we print the length of the DataFrame before and after dropping. Now we convert the different emojis to positive and negative sentiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44dafbf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@melemel2012 @JackPosobiec Great parenting üòä</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @copter_chief: .@realDonaldTrump Once AG Ba...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@mummybunz21 @shawneda @TheSims @TheSimCommuni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @JSimoncavage: I know I'm cute and this is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @GoldenTreeCIC: Repeat daily and develop a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0       @melemel2012 @JackPosobiec Great parenting üòä       1\n",
       "1  RT @copter_chief: .@realDonaldTrump Once AG Ba...       1\n",
       "2  @mummybunz21 @shawneda @TheSims @TheSimCommuni...       1\n",
       "3  RT @JSimoncavage: I know I'm cute and this is ...       1\n",
       "4  RT @GoldenTreeCIC: Repeat daily and develop a ...       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace({\"labels\": {'happy': 1, 'sad': 0, 'angry': 0, 'love': 1}}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ea4ea1",
   "metadata": {},
   "source": [
    "Next, we divide our data in two hold-out splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fd28e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(df.text, df.labels, stratify=df.labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f13d69",
   "metadata": {},
   "source": [
    "There are two important things to be discussed here. The first one is stratifying based on the label distribution and the second one is setting a seed with ``random_state``. The latter is important for reproducibility; ``scikit-learn`` by default randomly shuffles the data (to avoid the order playing a part in the predictions). To make sure that it is the same random shuffle every time, we provide a seed. Now we can run our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ff6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "cv = TfidfVectorizer()\n",
    "Xf_train = cv.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fbebf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(Xf_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e76029",
   "metadata": {},
   "source": [
    "Notice that we again have a seed, this time for our Logistic Regression model, as we need to fix the randomness in the solver. Always check the documentation if there is a seed possibility somewhere. Even numpy has a seed. Now we check performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aa59da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.45      0.54       530\n",
      "           1       0.74      0.88      0.81       951\n",
      "\n",
      "    accuracy                           0.73      1481\n",
      "   macro avg       0.71      0.67      0.67      1481\n",
      "weighted avg       0.72      0.73      0.71      1481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = lr.predict(cv.transform(X_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247947c",
   "metadata": {},
   "source": [
    "Here we can see Precision, Recall, Accuracy, F1 score, class frequencies, everything. These figures are meaningless without a baseline, so let‚Äôs use a majority one, predicting 1 for all instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da50f55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       530\n",
      "           1       0.64      1.00      0.78       951\n",
      "\n",
      "    accuracy                           0.64      1481\n",
      "   macro avg       0.32      0.50      0.39      1481\n",
      "weighted avg       0.41      0.64      0.50      1481\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20214772\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\20214772\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\20214772\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, len(y_pred) * [1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651c350f",
   "metadata": {},
   "source": [
    "Note that we replaced the actual predictions with a list having the length of the dataset instances. You are encouraged to try other classifiers, but as you can see, the performance is pretty bad. The performance can undoubtedly be improved with more data collection, but we will decide that we can not currently reproduce the data collection method for this practical. Therefore, we will focus on this benchmark data ‚Äîas that is also Twitter‚Äî and see if we can use simple models to predict Yelp reviews. \n",
    "This would at least give us some indication of the Emoji idea is worth pursuing.\n",
    "\n",
    "#### Preparing the out-of-domain Data\n",
    "\n",
    "The out-of-domain (meaning it is a different domain than the data of interest) data was gathered from Kaggle. As we can see, it contains a few labels in addition to the review score, but we‚Äôre only interested in the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a25bf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir + 'yelp.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39802a80",
   "metadata": {},
   "source": [
    "Now we also want to have a careful look at those labels. Note that we overwrite the previous ``df`` as we stored it in train and test splits, and we do not want to keep big dataframe objects in memory if they are unused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3396eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAXR0lEQVR4nO3df4zU9Z3H8edL5CxhFTDYPQrcQXL0cggplQ3HxdjMVnLuqXfYpCYYT+XqhZ6hlzYlqdg/rjaGHH+UtrFW77ZHAx62G3KtB0HpHfXcGBMpBY92ReTc1I3lRyCtiGzPcIG+74/52IzrsDPznZ0Z9PN6JJP5zuf7/czn/f3M7IuZ73xnUERgZmZ5uKzTBZiZWfs49M3MMuLQNzPLiEPfzCwjDn0zs4xc3ukCapk5c2bMmzevUN/f/OY3TJ06dWILmgCuqzGuqzGuqzEf1LoOHDjwq4i45j0rIuKSvixdujSKevbZZwv3bSXX1RjX1RjX1ZgPal3A/qiSqT68Y2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhmpGfqSPiRpn6SfSTok6aup/UFJxyQdTJebK/o8IGlY0hFJN1W0L5U0lNY9LEmt2S0zM6umnm/kngM+GRGjkiYDz0vandZ9IyK+VrmxpIXAKuBa4CPAjyV9NCIuAI8Ba4C9wNNAH7AbMzNri5qhn77ZNZpuTk6X8f7nlZXAQEScA16TNAwskzQCXBURLwBIehy4DYe+2fvGvPVPFe67bvF5VhfsP7LxlsLj2rsp6vifsyRNAg4AfwR8OyLul/QgsBp4C9gPrIuI05IeAfZGxLbUdzPlYB8BNkbEitR+A3B/RNxaZbw1lN8R0N3dvXRgYKDQzo2OjtLV1VWobyu5rsa4rsa0sq6hY2cK9+2eAiffLtZ38exphcet5YP6OPb29h6IiJ6x7XX94Fo6NLNE0nTgSUmLKB+qeYjyq/6HgE3AZ4Bqx+ljnPZq4/UD/QA9PT1RKpXqKfM9BgcHKdq3lVxXY1xXY1pZV9FX6lB+pb9pqNhvPI7cWSo8bi25PY4Nnb0TEW8Cg0BfRJyMiAsR8VvgO8CytNlRYG5FtznA8dQ+p0q7mZm1ST1n71yTXuEjaQqwAnhF0qyKzT4FvJSWdwKrJF0haT6wANgXESeAs5KWp7N27gZ2TNyumJlZLfW815oFbE3H9S8DtkfELkn/KmkJ5UM0I8BnASLikKTtwMvAeWBtOjwEcB+wBZhC+Ti/P8Q1M2ujes7e+Tnw8Srtd43TZwOwoUr7fmBRgzWamdkE8Tdyzcwy4tA3M8uIQ9/MLCMOfTOzjBT7poSZWSaa+emJZmzpm9qS+/UrfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8tIzdCX9CFJ+yT9TNIhSV9N7VdL2iPp1XQ9o6LPA5KGJR2RdFNF+1JJQ2ndw5LUmt0yM7Nq6nmlfw74ZER8DFgC9ElaDqwHnomIBcAz6TaSFgKrgGuBPuBRSZPSfT0GrAEWpEvfxO2KmZnVUjP0o2w03ZycLgGsBLam9q3AbWl5JTAQEeci4jVgGFgmaRZwVUS8EBEBPF7Rx8zM2qCuY/qSJkk6CJwC9kTET4DuiDgBkK4/nDafDfyyovvR1DY7LY9tNzOzNlH5RXedG0vTgSeBvweej4jpFetOR8QMSd8GXoiIbal9M/A08DrwjxGxIrXfAHwpIv6yyjhrKB8Goru7e+nAwEChnRsdHaWrq6tQ31ZyXY1xXY1pZV1Dx84U7ts9BU6+Xazv4tnTCo9bS635amafmzF/2qSmHsfe3t4DEdEztr2h/xg9It6UNEj5WPxJSbMi4kQ6dHMqbXYUmFvRbQ5wPLXPqdJebZx+oB+gp6cnSqVSI2X+zuDgIEX7tpLraozrakwr61rdxH8Svm7xeTYNNRQ5vzNyZ6nwuLXUmq9m9rkZW/qmtuRxrOfsnWvSK3wkTQFWAK8AO4F70mb3ADvS8k5glaQrJM2n/IHtvnQI6Kyk5emsnbsr+piZWRvU88/uLGBrOgPnMmB7ROyS9AKwXdK9lA/d3A4QEYckbQdeBs4DayPiQrqv+4AtwBRgd7qYmVmb1Az9iPg58PEq7b8GbrxInw3Ahirt+4FFjZdpZmYTwd/INTPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLSM3QlzRX0rOSDks6JOnzqf1BScckHUyXmyv6PCBpWNIRSTdVtC+VNJTWPSxJrdktMzOr5vI6tjkPrIuIFyVdCRyQtCet+0ZEfK1yY0kLgVXAtcBHgB9L+mhEXAAeA9YAe4GngT5g98TsipmZ1VLzlX5EnIiIF9PyWeAwMHucLiuBgYg4FxGvAcPAMkmzgKsi4oWICOBx4LZmd8DMzOqncv7WubE0D3gOWAR8EVgNvAXsp/xu4LSkR4C9EbEt9dlM+dX8CLAxIlak9huA+yPi1irjrKH8joDu7u6lAwMDhXZudHSUrq6uQn1byXU1xnU1ppV1DR07U7hv9xQ4+XaxvotnTys8bi215quZfW7G/GmTmnoce3t7D0REz9j2eg7vACCpC/gB8IWIeEvSY8BDQKTrTcBngGrH6WOc9vc2RvQD/QA9PT1RKpXqLfNdBgcHKdq3lVxXY1xXY1pZ1+r1TxXuu27xeTYN1R057zJyZ6nwuLXUmq9m9rkZW/qmtuRxrOvsHUmTKQf+ExHxQ4CIOBkRFyLit8B3gGVp86PA3Iruc4DjqX1OlXYzM2uTes7eEbAZOBwRX69on1Wx2aeAl9LyTmCVpCskzQcWAPsi4gRwVtLydJ93AzsmaD/MzKwO9bzXuh64CxiSdDC1fRm4Q9ISyodoRoDPAkTEIUnbgZcpn/mzNp25A3AfsAWYQvk4v8/cMTNro5qhHxHPU/14/NPj9NkAbKjSvp/yh8BmZtYB/kaumVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWkZqhL2mupGclHZZ0SNLnU/vVkvZIejVdz6jo84CkYUlHJN1U0b5U0lBa97Ckav/hupmZtUg9r/TPA+si4k+A5cBaSQuB9cAzEbEAeCbdJq1bBVwL9AGPSpqU7usxYA2wIF36JnBfzMyshpqhHxEnIuLFtHwWOAzMBlYCW9NmW4Hb0vJKYCAizkXEa8AwsEzSLOCqiHghIgJ4vKKPmZm1gcr5W+fG0jzgOWAR8HpETK9YdzoiZkh6BNgbEdtS+2ZgNzACbIyIFan9BuD+iLi1yjhrKL8joLu7e+nAwEChnRsdHaWrq6tQ31ZyXY1xXY1pZV1Dx84U7ts9BU6+Xazv4tnTCo9bS635amafmzF/2qSmHsfe3t4DEdEztv3yeu9AUhfwA+ALEfHWOIfjq62Icdrf2xjRD/QD9PT0RKlUqrfMdxkcHKRo31ZyXY1xXY1pZV2r1z9VuO+6xefZNFR35LzLyJ2lwuPWUmu+mtnnZmzpm9qSx7Gus3ckTaYc+E9ExA9T88l0yIZ0fSq1HwXmVnSfAxxP7XOqtJuZWZvUc/aOgM3A4Yj4esWqncA9afkeYEdF+ypJV0iaT/kD230RcQI4K2l5us+7K/qYmVkb1PNe63rgLmBI0sHU9mVgI7Bd0r3A68DtABFxSNJ24GXKZ/6sjYgLqd99wBZgCuXj/LsnZjfMzKweNUM/Ip6n+vF4gBsv0mcDsKFK+37KHwKbmVkH+Bu5ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZqRn6kr4r6ZSklyraHpR0TNLBdLm5Yt0DkoYlHZF0U0X7UklDad3DkjTxu2NmZuOp55X+FqCvSvs3ImJJujwNIGkhsAq4NvV5VNKktP1jwBpgQbpUu08zM2uhmqEfEc8Bb9R5fyuBgYg4FxGvAcPAMkmzgKsi4oWICOBx4LaCNZuZWUEqZ3CNjaR5wK6IWJRuPwisBt4C9gPrIuK0pEeAvRGxLW23GdgNjAAbI2JFar8BuD8ibr3IeGsovyugu7t76cDAQKGdGx0dpaurq1DfVnJdjXFdjWllXUPHzhTu2z0FTr5drO/i2dMKj1tLrflqZp+bMX/apKYex97e3gMR0TO2/fKC9/cY8BAQ6XoT8Bmg2nH6GKe9qojoB/oBenp6olQqFSpycHCQon1byXU1xnU1ppV1rV7/VOG+6xafZ9NQscgZubNUeNxaas1XM/vcjC19U1vyOBZ6BCLi5DvLkr4D7Eo3jwJzKzadAxxP7XOqtJu9bw0dO9OxQBjZeEtHxrX3v0KnbKZj9O/4FPDOmT07gVWSrpA0n/IHtvsi4gRwVtLydNbO3cCOJuo2M7MCar7Sl/R9oATMlHQU+ApQkrSE8iGaEeCzABFxSNJ24GXgPLA2Ii6ku7qP8plAUygf5989gfthZmZ1qBn6EXFHlebN42y/AdhQpX0/sKih6szMbEL5G7lmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGaoa+pO9KOiXppYq2qyXtkfRqup5Rse4BScOSjki6qaJ9qaShtO5hSZr43TEzs/HU80p/C9A3pm098ExELACeSbeRtBBYBVyb+jwqaVLq8xiwBliQLmPv08zMWqxm6EfEc8AbY5pXAlvT8lbgtor2gYg4FxGvAcPAMkmzgKsi4oWICODxij5mZtYmKmdwjY2kecCuiFiUbr8ZEdMr1p+OiBmSHgH2RsS21L4Z2A2MABsjYkVqvwG4PyJuvch4ayi/K6C7u3vpwMBAoZ0bHR2lq6urUN9Wcl2NuVTrOvXGGU6+3ZmxF8+edtF1rZyvoWNnCvftnkLh+Rpvf5tVa76a2edmzJ82qanHsbe390BE9Ixtv7ypqt6r2nH6GKe9qojoB/oBenp6olQqFSpmcHCQon1byXU15lKt61tP7GDT0ET/CdVn5M7SRde1cr5Wr3+qcN91i88Xnq/x9rdZtearmX1uxpa+qS15HIuevXMyHbIhXZ9K7UeBuRXbzQGOp/Y5VdrNzKyNiob+TuCetHwPsKOifZWkKyTNp/yB7b6IOAGclbQ8nbVzd0UfMzNrk5rvtSR9HygBMyUdBb4CbAS2S7oXeB24HSAiDknaDrwMnAfWRsSFdFf3UT4TaArl4/y7J3RPDIB5Tb79LvpWdmTjLYXHNbP2qRn6EXHHRVbdeJHtNwAbqrTvBxY1VJ2ZmU0ofyPXzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjnfmJwDYZOnamI7+Q558kMLNLlV/pm5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpaRpkJf0oikIUkHJe1PbVdL2iPp1XQ9o2L7ByQNSzoi6aZmizczs8ZMxCv93ohYEhE96fZ64JmIWAA8k24jaSGwCrgW6AMelTRpAsY3M7M6teLwzkpga1reCtxW0T4QEeci4jVgGFjWgvHNzOwiFBHFO0uvAaeBAP45IvolvRkR0yu2OR0RMyQ9AuyNiG2pfTOwOyL+rcr9rgHWAHR3dy8dGBgoVN+pN85w8u1CXZuyePa0cdePjo7S1dXVkrGHjp0p3Ld7CoXnq9Y+N6OV89WMTj2/YPz59vOrMbXmq5l9bsb8aZOaehx7e3sPVByB+Z1mf1r5+og4LunDwB5Jr4yzraq0Vf0XJyL6gX6Anp6eKJVKhYr71hM72DTU/l+PHrmzNO76wcFBiu5TLc38lPS6xecLz1etfW5GK+erGZ16fsH48+3nV2NqzVcnfp4dYEvf1JY8jk0d3omI4+n6FPAk5cM1JyXNAkjXp9LmR4G5Fd3nAMebGd/MzBpTOPQlTZV05TvLwJ8DLwE7gXvSZvcAO9LyTmCVpCskzQcWAPuKjm9mZo1r5r1pN/CkpHfu53sR8SNJPwW2S7oXeB24HSAiDknaDrwMnAfWRsSFpqo3M7OGFA79iPgF8LEq7b8GbrxInw3AhqJjmplZc/yNXDOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjLQ99CX1SToiaVjS+naPb2aWs7aGvqRJwLeBvwAWAndIWtjOGszMctbuV/rLgOGI+EVE/B8wAKxscw1mZtlSRLRvMOnTQF9E/G26fRfwpxHxuTHbrQHWpJt/DBwpOORM4FcF+7aS62qM62qM62rMB7WuP4yIa8Y2Xt7EHRahKm3v+VcnIvqB/qYHk/ZHRE+z9zPRXFdjXFdjXFdjcqur3Yd3jgJzK27PAY63uQYzs2y1O/R/CiyQNF/S7wGrgJ1trsHMLFttPbwTEeclfQ74D2AS8N2IONTCIZs+RNQirqsxrqsxrqsxWdXV1g9yzcyss/yNXDOzjDj0zcwy8r4PfUnflXRK0ksXWS9JD6efffi5pOsukbpKks5IOpgu/9CmuuZKelbSYUmHJH2+yjZtn7M662r7nEn6kKR9kn6W6vpqlW06MV/11NWR51gae5Kk/5a0q8q6jvxN1lFXp/4mRyQNpTH3V1k/sfMVEe/rC/AJ4DrgpYusvxnYTfk7AsuBn1widZWAXR2Yr1nAdWn5SuB/gIWdnrM662r7nKU56ErLk4GfAMsvgfmqp66OPMfS2F8Evldt/E79TdZRV6f+JkeAmeOsn9D5et+/0o+I54A3xtlkJfB4lO0FpkuadQnU1RERcSIiXkzLZ4HDwOwxm7V9zuqsq+3SHIymm5PTZezZD52Yr3rq6ghJc4BbgH+5yCYd+Zuso65L1YTO1/s+9OswG/hlxe2jXAJhkvxZenu+W9K17R5c0jzg45RfJVbq6JyNUxd0YM7SIYGDwClgT0RcEvNVR13QmefYN4EvAb+9yPpOPb++yfh1QWfmK4D/lHRA5Z+gGWtC5yuH0K/rpx864EXKv43xMeBbwL+3c3BJXcAPgC9ExFtjV1fp0pY5q1FXR+YsIi5ExBLK3yBfJmnRmE06Ml911NX2+ZJ0K3AqIg6Mt1mVtpbOV511depv8vqIuI7yrw+vlfSJMesndL5yCP1L8qcfIuKtd96eR8TTwGRJM9sxtqTJlIP1iYj4YZVNOjJnterq5JylMd8EBoG+Mas6+hy7WF0dmq/rgb+SNEL5V3Q/KWnbmG06MV816+rU8ysijqfrU8CTlH+NuNKEzlcOob8TuDt9Ar4cOBMRJzpdlKTfl6S0vIzyY/HrNowrYDNwOCK+fpHN2j5n9dTViTmTdI2k6Wl5CrACeGXMZp2Yr5p1dWK+IuKBiJgTEfMo/8zKf0XEX4/ZrO3zVU9dHXp+TZV05TvLwJ8DY8/4m9D5avevbE44Sd+n/Kn7TElHga9Q/lCLiPgn4GnKn34PA/8L/M0lUtengfsknQfeBlZF+qi+xa4H7gKG0vFggC8Df1BRWyfmrJ66OjFns4CtKv8HQJcB2yNil6S/q6irE/NVT12deo69xyUwX/XU1Yn56gaeTP/WXA58LyJ+1Mr58s8wmJllJIfDO2Zmljj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8vI/wOhB0AgBC4OJQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = df.stars.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c29519",
   "metadata": {},
   "source": [
    "As you can see, the data has mostly positive labels. Before we proceed, we have to talk about what this set has to do with sentiment prediction. There are no labels for positive and negative, right? It turns out that (unsurprisingly) review scores are actually a good proxy for sentiment recognition!\n",
    "\n",
    "However, we will have to push these scores to positive/negative somehow. Given the uneven label distribution, we might want to make a selection for this binary task specifically. Firstly, we replace items in the column stars by values we provide (either 1, -1, or 0). In this encoding, one will be positive, zero will be negative, and we will use -1 as an identifier for the rows we want to delete. In the next line, we first locate all the rows where df.stars is -1, and get their index (drop needs indices). Both replace and drop will be done ``inplace`` so no need to do a ``df =`` there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "771c11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({\"stars\": {5: 1, 4: -1, 3: -1, 2: 0, 1: 0}}, inplace=True)\n",
    "df.drop(df.loc[df.stars == -1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e073134b",
   "metadata": {},
   "source": [
    "Now we can put them in separate train and test splits, which we want to store separately because this will be our data to test generalization. We will therefore prepend them with an underscore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d61e9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_X_train, _X_test, _y_train, _y_test = train_test_split(df.text, df.stars, stratify=df.stars, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea10cbc",
   "metadata": {},
   "source": [
    "You can see that our test set is not extremely imbalanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb594e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'stars'}>]], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(_y_test).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bcc9fc",
   "metadata": {},
   "source": [
    "Now, let us again determine how difficult this task is with a simple Logistic Regression baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b42f669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83       419\n",
      "           1       0.88      0.97      0.93       835\n",
      "\n",
      "    accuracy                           0.90      1254\n",
      "   macro avg       0.91      0.86      0.88      1254\n",
      "weighted avg       0.90      0.90      0.89      1254\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       419\n",
      "           1       0.67      1.00      0.80       835\n",
      "\n",
      "    accuracy                           0.67      1254\n",
      "   macro avg       0.33      0.50      0.40      1254\n",
      "weighted avg       0.44      0.67      0.53      1254\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20214772\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\20214772\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\20214772\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cv = TfidfVectorizer()\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(cv.fit_transform(_X_train), _y_train)\n",
    "_y_pred = lr.predict(cv.transform(_X_test))\n",
    "print(classification_report(_y_test, _y_pred))\n",
    "print(classification_report(_y_test, len(_y_pred) * [1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd71fc3",
   "metadata": {},
   "source": [
    "If we input the same random_states, this model should report an accuracy of about 90%, and the baseline is 67%. The F1 scores for LR are also significantly higher. Anyways, good news! We can actually predict if something gets a low or a high score. Finally, let us prepare our Twitter data. This is actually a dictionary / JSON file in the following code, but it is stored in a pickle format, which is a binary image of the Python object. We simply load it, select the entries we want: ``texts`` and ``labels`` (the latter of which is under ``info``) and put that in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3cdfcf20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Listening to the \"New Age\" station on @Slacker...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i didnt mean knee high I ment in lengt it goes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I wana see the vid Kyan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if my mom went on for the love of ray J or any...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Mrhilton1985 Welcome to Twitter xx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@kjbmusic oh yeah... however, I'd still like t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I need a nice tea-drinking pic for our #Tea Cl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@JonathanRKnight so twitpic it lol, I love Hom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@BarCough it's enough to make you sick, eh? th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\"Iran, with its unity and God's grace, will pu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  labels\n",
       "0  Listening to the \"New Age\" station on @Slacker...       1\n",
       "1  i didnt mean knee high I ment in lengt it goes...       1\n",
       "2                            I wana see the vid Kyan       1\n",
       "3  if my mom went on for the love of ray J or any...       0\n",
       "4                @Mrhilton1985 Welcome to Twitter xx       1\n",
       "5  @kjbmusic oh yeah... however, I'd still like t...       1\n",
       "6  I need a nice tea-drinking pic for our #Tea Cl...       1\n",
       "7  @JonathanRKnight so twitpic it lol, I love Hom...       1\n",
       "8  @BarCough it's enough to make you sick, eh? th...       0\n",
       "9  \"Iran, with its unity and God's grace, will pu...       0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data = pickle.load(open(data_dir + 'twitter.pickle', 'rb'))\n",
    "df = pd.DataFrame({'texts': data['texts'], 'labels': [x['label'] for x in data['info']]})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40c8fd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAASpklEQVR4nO3df6zd9X3f8edrdkOJvYAZzZVl09md3B8GGqncMdZs1fWYhJNWNZOK5Iw2JkOy2rIsmyItppPGH5MloilTm6S0skJqR0G580hWu6O0Re5u6dQ4DJo0xrgUNzDi4OGmJCSXRjQm7/1xvkhnzjU+95x7z8m9n+dDujrf7+f7+ZzP521br/v1937P96aqkCS14e9MegGSpPEx9CWpIYa+JDXE0Jekhhj6ktSQtZNewKVcffXVtWXLlqHGvvLKK6xbt25pF/Q9zprb0FrNrdULo9f8xBNPfLWqfuDC9u/50N+yZQuPP/74UGPn5uaYmZlZ2gV9j7PmNrRWc2v1wug1J/k/C7V7eUeSGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhryPf+JXEmapC37HprIvAd3Ls9jJzzTl6SGGPqS1BBDX5IaYuhLUkMuGfpJPp7kXJIn+9r+c5I/T/LFJP89yZV9x+5OcjrJ00lu6Wu/IcmJ7tiHk2TJq5EkvaFBzvQPAjsvaHsEuK6qfhz4C+BugCTbgd3Atd2Y+5Ks6cb8BrAX2NZ9XfiekqRldsnQr6pHgZcuaPuDqjrf7R4HNnfbu4DZqnq1qp4FTgM3JtkIvKWqPltVBXwCuHWJapAkDWgp7tP/V8B/7bY30fsm8LozXdu3u+0L2xeUZC+9/xUwNTXF3NzcUAubn58feuxKZc1taK3mSdb7/uvPX7rTMliumkcK/ST/ATgPPPB60wLd6g3aF1RVB4ADANPT0zXsrwzzV6y1wZpXv0nWe8cEP5y1HDUPHfpJ9gA/A9zcXbKB3hn8NX3dNgMvdO2bF2iXJI3RULdsJtkJfAD42ar6m75DR4HdSS5LspXeD2wfq6qzwDeT3NTdtfNu4MiIa5ckLdIlz/STfAqYAa5Ocga4h97dOpcBj3R3Xh6vql+sqpNJDgNP0bvsc1dVvda91S/RuxPocuDh7kuSNEaXDP2qetcCzfe/Qf/9wP4F2h8HrlvU6iRJS8pP5EpSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpyydBP8vEk55I82dd2VZJHkjzTvW7oO3Z3ktNJnk5yS1/7DUlOdMc+nCRLX44k6Y0McqZ/ENh5Qds+4FhVbQOOdfsk2Q7sBq7txtyXZE035jeAvcC27uvC95QkLbNLhn5VPQq8dEHzLuBQt30IuLWvfbaqXq2qZ4HTwI1JNgJvqarPVlUBn+gbI0kak7VDjpuqqrMAVXU2yVu79k3A8b5+Z7q2b3fbF7YvKMleev8rYGpqirm5uaEWOT8/P/TYlcqa29BazZOs9/3Xn5/IvMtV87ChfzELXaevN2hfUFUdAA4ATE9P18zMzFCLmZubY9ixK5U1t6G1midZ7x37HprIvAd3rluWmoe9e+fF7pIN3eu5rv0McE1fv83AC1375gXaJUljNGzoHwX2dNt7gCN97buTXJZkK70f2D7WXQr6ZpKburt23t03RpI0Jpe8vJPkU8AMcHWSM8A9wL3A4SR3As8DtwFU1ckkh4GngPPAXVX1WvdWv0TvTqDLgYe7L0nSGF0y9KvqXRc5dPNF+u8H9i/Q/jhw3aJWJ0laUn4iV5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpyyd+ctZKd+MrLE/lN9s/d+9Njn1OSBuGZviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWrISKGf5N8lOZnkySSfSvL9Sa5K8kiSZ7rXDX39705yOsnTSW4ZffmSpMUYOvSTbAL+DTBdVdcBa4DdwD7gWFVtA451+yTZ3h2/FtgJ3JdkzWjLlyQtxqiXd9YClydZC7wZeAHYBRzqjh8Cbu22dwGzVfVqVT0LnAZuHHF+SdIipKqGH5y8D9gPfAv4g6q6PcnXq+rKvj5fq6oNST4KHK+qT3bt9wMPV9WDC7zvXmAvwNTU1A2zs7NDre/cSy/z4reGGjqS6zddMf5JO/Pz86xfv35i80+CNa9+k6z3xFdensi8W69YM1LNO3bseKKqpi9sH/oxDN21+l3AVuDrwH9L8vNvNGSBtgW/41TVAeAAwPT0dM3MzAy1xo88cIQPnRj/kyaeu31m7HO+bm5ujmH/vFYqa179JlnvJB7lAnBw57plqXmUyzv/HHi2qv6qqr4NfAb4SeDFJBsButdzXf8zwDV94zfTuxwkSRqTUUL/eeCmJG9OEuBm4BRwFNjT9dkDHOm2jwK7k1yWZCuwDXhshPklSYs09LWPqvpckgeBPwXOA5+nd0lmPXA4yZ30vjHc1vU/meQw8FTX/66qem3E9UuSFmGkC95VdQ9wzwXNr9I761+o/356P/iVJE2An8iVpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1ZKTQT3JlkgeT/HmSU0n+cZKrkjyS5JnudUNf/7uTnE7ydJJbRl++JGkxRj3T/zXg96rqR4G3AaeAfcCxqtoGHOv2SbId2A1cC+wE7kuyZsT5JUmLMHToJ3kL8FPA/QBV9bdV9XVgF3Co63YIuLXb3gXMVtWrVfUscBq4cdj5JUmLN8qZ/g8BfwX8VpLPJ/lYknXAVFWdBehe39r13wR8uW/8ma5NkjQmqarhBibTwHHg7VX1uSS/BnwDeG9VXdnX72tVtSHJrwOfrapPdu33A79bVZ9e4L33AnsBpqambpidnR1qjedeepkXvzXU0JFcv+mK8U/amZ+fZ/369RObfxKsefWbZL0nvvLyRObdesWakWresWPHE1U1fWH72hHWdAY4U1Wf6/YfpHf9/sUkG6vqbJKNwLm+/tf0jd8MvLDQG1fVAeAAwPT0dM3MzAy1wI88cIQPnRilxOE8d/vM2Od83dzcHMP+ea1U1rz6TbLeO/Y9NJF5D+5ctyw1D315p6r+L/DlJD/SNd0MPAUcBfZ0bXuAI932UWB3ksuSbAW2AY8NO78kafFGPQ1+L/BAkjcBXwLeQ+8byeEkdwLPA7cBVNXJJIfpfWM4D9xVVa+NOL8kaRFGCv2q+gLwXdeM6J31L9R/P7B/lDklScPzE7mS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGjBz6SdYk+XyS/9HtX5XkkSTPdK8b+vreneR0kqeT3DLq3JKkxVmKM/33Aaf69vcBx6pqG3Cs2yfJdmA3cC2wE7gvyZolmF+SNKCRQj/JZuCngY/1Ne8CDnXbh4Bb+9pnq+rVqnoWOA3cOMr8kqTFGfVM/1eBfw98p69tqqrOAnSvb+3aNwFf7ut3pmuTJI3J2mEHJvkZ4FxVPZFkZpAhC7TVRd57L7AXYGpqirm5uaHWOHU5vP/680ONHcWw610K8/PzE51/Eqx59ZtkvZPIEFi+mocOfeDtwM8meSfw/cBbknwSeDHJxqo6m2QjcK7rfwa4pm/8ZuCFhd64qg4ABwCmp6drZmZmqAV+5IEjfOjEKCUO57nbZ8Y+5+vm5uYY9s9rpbLm1W+S9d6x76GJzHtw57plqXnoyztVdXdVba6qLfR+QPuHVfXzwFFgT9dtD3Ck2z4K7E5yWZKtwDbgsaFXLklatOU4Db4XOJzkTuB54DaAqjqZ5DDwFHAeuKuqXluG+SVJF7EkoV9Vc8Bct/3XwM0X6bcf2L8Uc0qSFs9P5EpSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQ4YO/STXJPmfSU4lOZnkfV37VUkeSfJM97qhb8zdSU4neTrJLUtRgCRpcKOc6Z8H3l9VPwbcBNyVZDuwDzhWVduAY90+3bHdwLXATuC+JGtGWbwkaXGGDv2qOltVf9ptfxM4BWwCdgGHum6HgFu77V3AbFW9WlXPAqeBG4edX5K0eKmq0d8k2QI8ClwHPF9VV/Yd+1pVbUjyUeB4VX2ya78feLiqHlzg/fYCewGmpqZumJ2dHWpd5156mRe/NdTQkVy/6YrxT9qZn59n/fr1E5t/Eqx59ZtkvSe+8vJE5t16xZqRat6xY8cTVTV9YfvakVYFJFkPfBr4t1X1jSQX7bpA24LfcarqAHAAYHp6umZmZoZa20ceOMKHToxc4qI9d/vM2Od83dzcHMP+ea1U1rz6TbLeO/Y9NJF5D+5ctyw1j3T3TpLvoxf4D1TVZ7rmF5Ns7I5vBM517WeAa/qGbwZeGGV+SdLijHL3ToD7gVNV9V/6Dh0F9nTbe4Ajfe27k1yWZCuwDXhs2PklSYs3yrWPtwO/AJxI8oWu7VeAe4HDSe4EngduA6iqk0kOA0/Ru/Pnrqp6bYT5JUmLNHToV9X/YuHr9AA3X2TMfmD/sHNKkkbjJ3IlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNGXvoJ9mZ5Okkp5PsG/f8ktSysYZ+kjXArwPvALYD70qyfZxrkKSWjftM/0bgdFV9qar+FpgFdo15DZLUrLVjnm8T8OW+/TPAP7qwU5K9wN5udz7J00POdzXw1SHHDi0fHPeM/5+J1Dxh1rz6tVYvOz44cs1/f6HGcYd+Fmir72qoOgAcGHmy5PGqmh71fVYSa25DazW3Vi8sX83jvrxzBrimb38z8MKY1yBJzRp36P9vYFuSrUneBOwGjo55DZLUrLFe3qmq80n+NfD7wBrg41V1chmnHPkS0QpkzW1orebW6oVlqjlV33VJXZK0SvmJXElqiKEvSQ1ZFaF/qUc7pOfD3fEvJvmJSaxzqQxQ7+1dnV9M8idJ3jaJdS6lQR/fkeQfJnktyc+Nc33LYZCak8wk+UKSk0n+aNxrXGoD/Nu+IsnvJPmzrub3TGKdSyXJx5OcS/LkRY4vfXZV1Yr+ovcD4b8Efgh4E/BnwPYL+rwTeJje5wRuAj436XUvc70/CWzott+xkusdtOa+fn8I/C7wc5Ne9xj+nq8EngJ+sNt/66TXPYaafwX4YLf9A8BLwJsmvfYRav4p4CeAJy9yfMmzazWc6Q/yaIddwCeq5zhwZZKN417oErlkvVX1J1X1tW73OL3PQ6xkgz6+473Ap4Fz41zcMhmk5n8JfKaqngeoqpVe9yA1F/B3kwRYTy/0z493mUunqh6lV8PFLHl2rYbQX+jRDpuG6LNSLLaWO+mdKaxkl6w5ySbgXwC/OcZ1LadB/p5/GNiQZC7JE0nePbbVLY9Bav4o8GP0PtR5AnhfVX1nPMubiCXPrnE/hmE5DPJoh4Ee/7BCDFxLkh30Qv+fLOuKlt8gNf8q8IGqeq13ErjiDVLzWuAG4GbgcuCzSY5X1V8s9+KWySA13wJ8AfhnwD8AHknyx1X1jWVe26QseXathtAf5NEOq+nxDwPVkuTHgY8B76iqvx7T2pbLIDVPA7Nd4F8NvDPJ+ar67bGscOkN+u/6q1X1CvBKkkeBtwErNfQHqfk9wL3Vu+B9OsmzwI8Cj41niWO35Nm1Gi7vDPJoh6PAu7ufhN8EvFxVZ8e90CVyyXqT/CDwGeAXVvBZX79L1lxVW6tqS1VtAR4EfnkFBz4M9u/6CPBPk6xN8mZ6T6w9NeZ1LqVBan6e3v9sSDIF/AjwpbGucryWPLtW/Jl+XeTRDkl+sTv+m/Tu5ngncBr4G3pnCyvSgPX+R+DvAfd1Z77nawU/oXDAmleVQWquqlNJfg/4IvAd4GNVteCtfyvBgH/P/wk4mOQEvUsfH6iqFfvI5SSfAmaAq5OcAe4Bvg+WL7t8DIMkNWQ1XN6RJA3I0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kN+X/mStEGgzrfNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = df.labels.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb985aa4",
   "metadata": {},
   "source": [
    "The label distribution looks close to what we also found in our Tweets, promising! Let us run a final baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "859a64c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.43      0.54       216\n",
      "           1       0.69      0.89      0.78       313\n",
      "\n",
      "    accuracy                           0.70       529\n",
      "   macro avg       0.71      0.66      0.66       529\n",
      "weighted avg       0.71      0.70      0.68       529\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       216\n",
      "           1       0.59      1.00      0.74       313\n",
      "\n",
      "    accuracy                           0.59       529\n",
      "   macro avg       0.30      0.50      0.37       529\n",
      "weighted avg       0.35      0.59      0.44       529\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20214772\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\20214772\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\20214772\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.texts, df.labels, stratify=df.labels, random_state=42)\n",
    "cv = TfidfVectorizer()\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(cv.fit_transform(X_train), y_train)\n",
    "y_pred = lr.predict(cv.transform(X_test))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(classification_report(y_test, len(y_pred) * [1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87332ea",
   "metadata": {},
   "source": [
    "The Logistic Regression does not improve the Majority Baseline significantly: 10% the accuracy and 30% the F1 score, which is actually a good increase, but the final score is not that impressive. Therefore, there is plenty of room for tackling this task properly.\n",
    "\n",
    "### Experimental Set-up\n",
    "So far, we have only been pre-exploring data and ran some simple baselines. It is time to think about our experimental setup. How are we going to use this out-of-domain set to assess generalization? We can use the scores we obtained in the previous part to see how well our Twitter dataset generalizes. We will take the classification scores on that set, the Yelp dataset, and then see how far performance drops of the Twitter sentiment classifier to the Yelp dataset. Note that we purposefully ran models as baselines (in addition to the majority baseline), so we have a rough estimate of how an optimized pipeline should at the very least be expected to perform on this data. \n",
    "\n",
    "We would describe what models we run, which hyper-parameters we tune, what evaluations we use, etc. For the sake of simplicity, we will use ``tf*idf`` features, Logistic Regression, and evaluate our models on F1 score (as the sets are slightly unbalanced). We will run a grid search procedure to fine-tune some parameters and evaluate the best setting using 10-fold cross-validation.\n",
    "\n",
    "If we were to look at more models, nested cross-validation would be more appropriate. The potential models we apply should be simple. If you want to use other models such as Multinomial Naive Bayes or and k-Nearest Neighbors, feel free to change the code below.\n",
    "\n",
    "#### Tuning with Grid Search\n",
    "First, we will define a pipeline. This is a scikit-learn component that makes it convenient to change multiple components together. We can simply call ``pipeline.fit(some_data)`` and it will run all the components in order. We define it as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a84f9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "pipeline = Pipeline([\n",
    "                    ('cv', CountVectorizer()),\n",
    "                    ('tf', TfidfTransformer()),\n",
    "                    ('lr', LogisticRegression(random_state=42)),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e49ba4",
   "metadata": {},
   "source": [
    "This also makes it very convenient for grid search because the identifiers (cv, tf, lr) can be used to set parameter ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d281c96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'cv__max_df': (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'cv__ngram_range': ((1, 1), (1, 2)), # unigrams or bigrams\n",
    "    'tf__use_idf': (True, False),\n",
    "    'tf__norm': ('l1', 'l2'),\n",
    "    # 'lr__max_iter': (1000, ),\n",
    "    'lr__C': (1000, 1000, 10, 1, 0.01, 0.001, 0.0001, 0.00001),\n",
    "    # 'lr__penalty': ('l2', 'none'),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a86f7",
   "metadata": {},
   "source": [
    "The syntax here is ``id__parameter_name``. The parameter names can be found under their respective documentation pages. Using both our pipeline and the parameters, we can run a grid search procedure to fine-tune them. This will create a ‚Äòhidden‚Äô development/validation set in the cross-validation of the method itself‚Äî**so no need to split it ourselves**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fed5956e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 192 candidates, totalling 1920 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('cv', CountVectorizer()),\n",
       "                                       ('tf', TfidfTransformer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             param_grid={'cv__max_df': (0.5, 0.75, 1.0),\n",
       "                         'cv__ngram_range': ((1, 1), (1, 2)),\n",
       "                         'lr__C': (1000, 1000, 10, 1, 0.01, 0.001, 0.0001,\n",
       "                                   1e-05),\n",
       "                         'tf__norm': ('l1', 'l2'),\n",
       "                         'tf__use_idf': (True, False)},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings # to get rid of too much output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=10, verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f4bea",
   "metadata": {},
   "source": [
    "Note that we i) set a cross-validation procedure (cv=10) and ii) fit a grid search on our training split. This will automatically figure out the best performing set of parameters (and best model) for us. We can access these attributes as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d64a8d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.7455616591035745\n",
      "\t cv__max_df : 0.5\n",
      "\t cv__ngram_range : (1, 2)\n",
      "\t lr__C : 1000\n",
      "\t tf__norm : l2\n",
      "\t tf__use_idf : True\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score:\", grid_search.best_score_)\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t\", param_name, \":\", best_parameters[param_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a1bfbb",
   "metadata": {},
   "source": [
    "This will give us the score of the best-performing model and its hyper-parameters. Finally, we can extract that model from the grid search pipeline, and either re-fit it on the entire training dataset or immediately apply it to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "472415b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.65       216\n",
      "           1       0.75      0.83      0.79       313\n",
      "\n",
      "    accuracy                           0.74       529\n",
      "   macro avg       0.73      0.72      0.72       529\n",
      "weighted avg       0.73      0.74      0.73       529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = grid_search.best_estimator_\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f0e5e",
   "metadata": {},
   "source": [
    "After about five minutes, it should be done fitting (if you kept the original grid), and we know if our tuned model performs better than our naive ``tf*idf`` + LR baseline. Overall it should be about 5% better on all metrics. Not too shabby for only a few parameters and one model!\n",
    "\n",
    "**Important note.** Grid search is a time-intensive procedure and it can take a while depending on the hardware you have. Therefore, it might be the case that it takes longer than five minutes, as mentioned above. Patience is advised.\n",
    "\n",
    "#### Domain Generalization\n",
    "In the next step, we will explore how well our model generalizes to another domain (from Twitter data to Yelp data). Remember that we had saved them in ``_X_test`` and ``_y_test``, so these pieces of data can be used at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1a66410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.69      0.64       419\n",
      "           1       0.83      0.77      0.80       835\n",
      "\n",
      "    accuracy                           0.75      1254\n",
      "   macro avg       0.72      0.73      0.72      1254\n",
      "weighted avg       0.76      0.75      0.75      1254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_y_pred = clf.predict(_X_test)\n",
    "print(classification_report(_y_test, _y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b49d60",
   "metadata": {},
   "source": [
    "We can notice that we obtain similar performance on Yelp as on our test set! Although definitely lower than the Yelp model itself, this is a very promising result. Now, we can spend all our future research time collecting more emoji data, experimenting with different models, investigating the learned features, comparing the dataset with some descriptives, etc. However, that‚Äôs all for this practical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84502f4",
   "metadata": {},
   "source": [
    "**Interesting note.** This practical is related to a popular research sub-field in machine learning known as **transfer learning**. Such a sub-field focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. For example, knowledge gained while learning to recognize cars could apply when trying to recognize trucks. This area of research bears some relation to the long history of psychological literature on transfer learning, although practical ties between the two fields are limited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a62963b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
